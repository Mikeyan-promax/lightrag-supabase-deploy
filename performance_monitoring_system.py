#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ€§èƒ½ç›‘æ§ç³»ç»Ÿ

è¿™æ˜¯ä¸€ä¸ªä¼ä¸šçº§çš„æ€§èƒ½ç›‘æ§ç³»ç»Ÿï¼Œæä¾›å®æ—¶æŒ‡æ ‡æ”¶é›†ã€æ€§èƒ½åˆ†æã€ç“¶é¢ˆæ£€æµ‹å’Œå‘Šè­¦æœºåˆ¶ã€‚

ä¸»è¦ç‰¹æ€§:
- å®æ—¶æ€§èƒ½æŒ‡æ ‡æ”¶é›†ï¼ˆCPUã€å†…å­˜ã€ç½‘ç»œã€ç£ç›˜ï¼‰
- åº”ç”¨ç¨‹åºæ€§èƒ½ç›‘æ§ï¼ˆå“åº”æ—¶é—´ã€ååé‡ã€é”™è¯¯ç‡ï¼‰
- è‡ªå®šä¹‰æŒ‡æ ‡å’Œä¸šåŠ¡æŒ‡æ ‡ç›‘æ§
- æ™ºèƒ½å¼‚å¸¸æ£€æµ‹å’Œå‘Šè­¦
- æ€§èƒ½è¶‹åŠ¿åˆ†æå’Œé¢„æµ‹
- åˆ†å¸ƒå¼è¿½è¸ªå’Œé“¾è·¯åˆ†æ
- æ€§èƒ½ç“¶é¢ˆè‡ªåŠ¨è¯†åˆ«
- å®æ—¶ä»ªè¡¨æ¿å’ŒæŠ¥å‘Š
- å†å²æ•°æ®å­˜å‚¨å’ŒæŸ¥è¯¢
- å¤šç»´åº¦æ€§èƒ½åˆ†æ

ä½œè€…: AI Assistant
åˆ›å»ºæ—¶é—´: 2024
ç‰ˆæœ¬: 1.0.0
"""

import asyncio
import logging
import time
import threading
import json
import statistics
import psutil
import uuid
from abc import ABC, abstractmethod
from collections import defaultdict, deque
from dataclasses import dataclass, field, asdict
from datetime import datetime, timedelta
from enum import Enum, auto
from typing import (
    Any, Awaitable, Callable, Dict, List, Optional, Set, Tuple, Union,
    TypeVar, Generic, Protocol, runtime_checkable
)
import numpy as np
from concurrent.futures import ThreadPoolExecutor
import aiofiles
import aiohttp
from contextlib import asynccontextmanager

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# ç±»å‹å®šä¹‰
T = TypeVar('T')
MetricValue = Union[int, float]


class MetricType(Enum):
    """æŒ‡æ ‡ç±»å‹æšä¸¾"""
    COUNTER = "counter"              # è®¡æ•°å™¨ï¼ˆåªå¢ä¸å‡ï¼‰
    GAUGE = "gauge"                  # ä»ªè¡¨ï¼ˆå¯å¢å¯å‡ï¼‰
    HISTOGRAM = "histogram"          # ç›´æ–¹å›¾ï¼ˆåˆ†å¸ƒç»Ÿè®¡ï¼‰
    SUMMARY = "summary"              # æ‘˜è¦ï¼ˆåˆ†ä½æ•°ç»Ÿè®¡ï¼‰
    TIMER = "timer"                  # è®¡æ—¶å™¨
    RATE = "rate"                    # é€Ÿç‡


class AlertLevel(Enum):
    """å‘Šè­¦çº§åˆ«æšä¸¾"""
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"


class AlertStatus(Enum):
    """å‘Šè­¦çŠ¶æ€æšä¸¾"""
    ACTIVE = "active"
    RESOLVED = "resolved"
    SUPPRESSED = "suppressed"


@dataclass
class MetricPoint:
    """æŒ‡æ ‡æ•°æ®ç‚¹"""
    timestamp: float
    value: MetricValue
    labels: Dict[str, str] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "timestamp": self.timestamp,
            "value": self.value,
            "labels": self.labels
        }


@dataclass
class MetricSeries:
    """æŒ‡æ ‡æ—¶é—´åºåˆ—"""
    name: str
    metric_type: MetricType
    description: str = ""
    unit: str = ""
    labels: Dict[str, str] = field(default_factory=dict)
    points: deque = field(default_factory=lambda: deque(maxlen=1000))
    
    def add_point(self, value: MetricValue, timestamp: Optional[float] = None, labels: Optional[Dict[str, str]] = None):
        """æ·»åŠ æ•°æ®ç‚¹"""
        if timestamp is None:
            timestamp = time.time()
        
        point_labels = {**self.labels}
        if labels:
            point_labels.update(labels)
        
        point = MetricPoint(timestamp=timestamp, value=value, labels=point_labels)
        self.points.append(point)
    
    def get_latest_value(self) -> Optional[MetricValue]:
        """è·å–æœ€æ–°å€¼"""
        if not self.points:
            return None
        return self.points[-1].value
    
    def get_values_in_range(self, start_time: float, end_time: float) -> List[MetricPoint]:
        """è·å–æ—¶é—´èŒƒå›´å†…çš„å€¼"""
        return [
            point for point in self.points
            if start_time <= point.timestamp <= end_time
        ]
    
    def calculate_statistics(self, duration: float = 300.0) -> Dict[str, float]:
        """è®¡ç®—ç»Ÿè®¡ä¿¡æ¯"""
        current_time = time.time()
        start_time = current_time - duration
        
        values = [
            point.value for point in self.points
            if point.timestamp >= start_time and isinstance(point.value, (int, float))
        ]
        
        if not values:
            return {}
        
        return {
            "count": len(values),
            "min": min(values),
            "max": max(values),
            "mean": statistics.mean(values),
            "median": statistics.median(values),
            "std_dev": statistics.stdev(values) if len(values) > 1 else 0.0,
            "p95": np.percentile(values, 95) if values else 0.0,
            "p99": np.percentile(values, 99) if values else 0.0
        }


@dataclass
class Alert:
    """å‘Šè­¦ä¿¡æ¯"""
    alert_id: str
    name: str
    description: str
    level: AlertLevel
    status: AlertStatus = AlertStatus.ACTIVE
    metric_name: str = ""
    threshold_value: Optional[MetricValue] = None
    current_value: Optional[MetricValue] = None
    labels: Dict[str, str] = field(default_factory=dict)
    created_time: float = field(default_factory=time.time)
    updated_time: float = field(default_factory=time.time)
    resolved_time: Optional[float] = None
    
    def resolve(self):
        """è§£å†³å‘Šè­¦"""
        self.status = AlertStatus.RESOLVED
        self.resolved_time = time.time()
        self.updated_time = self.resolved_time
    
    def suppress(self):
        """æŠ‘åˆ¶å‘Šè­¦"""
        self.status = AlertStatus.SUPPRESSED
        self.updated_time = time.time()
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return asdict(self)


@dataclass
class AlertRule:
    """å‘Šè­¦è§„åˆ™"""
    rule_id: str
    name: str
    description: str
    metric_name: str
    condition: str  # æ¡ä»¶è¡¨è¾¾å¼ï¼Œå¦‚ "> 0.8", "< 100", "== 0"
    threshold: MetricValue
    level: AlertLevel
    duration: float = 60.0  # æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
    labels: Dict[str, str] = field(default_factory=dict)
    enabled: bool = True
    
    def evaluate(self, current_value: MetricValue) -> bool:
        """è¯„ä¼°å‘Šè­¦æ¡ä»¶"""
        if not self.enabled:
            return False
        
        try:
            if self.condition.startswith(">="):
                return current_value >= self.threshold
            elif self.condition.startswith("<="):
                return current_value <= self.threshold
            elif self.condition.startswith(">"): 
                return current_value > self.threshold
            elif self.condition.startswith("<"):
                return current_value < self.threshold
            elif self.condition.startswith("=="):
                return current_value == self.threshold
            elif self.condition.startswith("!="):
                return current_value != self.threshold
            else:
                return False
        except (TypeError, ValueError):
            return False


class SystemMetricsCollector:
    """ç³»ç»ŸæŒ‡æ ‡æ”¶é›†å™¨"""
    
    def __init__(self, collection_interval: float = 5.0):
        self.collection_interval = collection_interval
        self._running = False
        self._task: Optional[asyncio.Task] = None
        self._metrics_callback: Optional[Callable[[Dict[str, MetricValue]], None]] = None
    
    def set_metrics_callback(self, callback: Callable[[Dict[str, MetricValue]], None]):
        """è®¾ç½®æŒ‡æ ‡å›è°ƒå‡½æ•°"""
        self._metrics_callback = callback
    
    async def start(self):
        """å¯åŠ¨æ”¶é›†å™¨"""
        if self._running:
            return
        
        self._running = True
        self._task = asyncio.create_task(self._collection_loop())
        logger.info("ç³»ç»ŸæŒ‡æ ‡æ”¶é›†å™¨å¯åŠ¨")
    
    async def stop(self):
        """åœæ­¢æ”¶é›†å™¨"""
        if not self._running:
            return
        
        self._running = False
        if self._task:
            self._task.cancel()
            try:
                await self._task
            except asyncio.CancelledError:
                pass
        
        logger.info("ç³»ç»ŸæŒ‡æ ‡æ”¶é›†å™¨åœæ­¢")
    
    async def _collection_loop(self):
        """æ”¶é›†å¾ªç¯"""
        while self._running:
            try:
                metrics = await self._collect_system_metrics()
                if self._metrics_callback:
                    self._metrics_callback(metrics)
                
                await asyncio.sleep(self.collection_interval)
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"ç³»ç»ŸæŒ‡æ ‡æ”¶é›†å‡ºé”™: {e}")
                await asyncio.sleep(1.0)
    
    async def _collect_system_metrics(self) -> Dict[str, MetricValue]:
        """æ”¶é›†ç³»ç»ŸæŒ‡æ ‡"""
        # CPUæŒ‡æ ‡
        cpu_percent = psutil.cpu_percent(interval=None)
        cpu_count = psutil.cpu_count()
        
        # å†…å­˜æŒ‡æ ‡
        memory = psutil.virtual_memory()
        
        # ç£ç›˜æŒ‡æ ‡
        disk = psutil.disk_usage('/')
        
        # ç½‘ç»œæŒ‡æ ‡
        network = psutil.net_io_counters()
        
        # è¿›ç¨‹æŒ‡æ ‡
        process = psutil.Process()
        process_memory = process.memory_info()
        
        return {
            # CPUæŒ‡æ ‡
            "system.cpu.usage_percent": cpu_percent,
            "system.cpu.count": cpu_count,
            
            # å†…å­˜æŒ‡æ ‡
            "system.memory.total": memory.total,
            "system.memory.available": memory.available,
            "system.memory.used": memory.used,
            "system.memory.usage_percent": memory.percent,
            
            # ç£ç›˜æŒ‡æ ‡
            "system.disk.total": disk.total,
            "system.disk.used": disk.used,
            "system.disk.free": disk.free,
            "system.disk.usage_percent": (disk.used / disk.total) * 100,
            
            # ç½‘ç»œæŒ‡æ ‡
            "system.network.bytes_sent": network.bytes_sent,
            "system.network.bytes_recv": network.bytes_recv,
            "system.network.packets_sent": network.packets_sent,
            "system.network.packets_recv": network.packets_recv,
            
            # è¿›ç¨‹æŒ‡æ ‡
            "process.memory.rss": process_memory.rss,
            "process.memory.vms": process_memory.vms,
            "process.cpu.percent": process.cpu_percent(),
            "process.threads.count": process.num_threads(),
        }


class ApplicationMetricsCollector:
    """åº”ç”¨ç¨‹åºæŒ‡æ ‡æ”¶é›†å™¨"""
    
    def __init__(self):
        self._request_count = 0
        self._error_count = 0
        self._response_times: deque = deque(maxlen=1000)
        self._active_requests = 0
        self._start_time = time.time()
        self._lock = threading.Lock()
    
    def record_request(self, response_time: float, is_error: bool = False):
        """è®°å½•è¯·æ±‚"""
        with self._lock:
            self._request_count += 1
            if is_error:
                self._error_count += 1
            self._response_times.append(response_time)
    
    def start_request(self):
        """å¼€å§‹è¯·æ±‚"""
        with self._lock:
            self._active_requests += 1
    
    def end_request(self):
        """ç»“æŸè¯·æ±‚"""
        with self._lock:
            self._active_requests = max(0, self._active_requests - 1)
    
    def get_metrics(self) -> Dict[str, MetricValue]:
        """è·å–åº”ç”¨æŒ‡æ ‡"""
        with self._lock:
            uptime = time.time() - self._start_time
            
            # è®¡ç®—å“åº”æ—¶é—´ç»Ÿè®¡
            response_times = list(self._response_times)
            avg_response_time = statistics.mean(response_times) if response_times else 0.0
            p95_response_time = np.percentile(response_times, 95) if response_times else 0.0
            p99_response_time = np.percentile(response_times, 99) if response_times else 0.0
            
            # è®¡ç®—é”™è¯¯ç‡
            error_rate = (self._error_count / max(1, self._request_count)) * 100
            
            # è®¡ç®—ååé‡ï¼ˆæ¯ç§’è¯·æ±‚æ•°ï¼‰
            throughput = self._request_count / max(1, uptime)
            
            return {
                "app.requests.total": self._request_count,
                "app.requests.errors": self._error_count,
                "app.requests.active": self._active_requests,
                "app.requests.error_rate": error_rate,
                "app.requests.throughput": throughput,
                "app.response_time.avg": avg_response_time,
                "app.response_time.p95": p95_response_time,
                "app.response_time.p99": p99_response_time,
                "app.uptime": uptime
            }


class AnomalyDetector:
    """å¼‚å¸¸æ£€æµ‹å™¨"""
    
    def __init__(self, window_size: int = 100, sensitivity: float = 2.0):
        self.window_size = window_size
        self.sensitivity = sensitivity  # æ ‡å‡†å·®å€æ•°
        self._history: Dict[str, deque] = defaultdict(lambda: deque(maxlen=window_size))
    
    def add_value(self, metric_name: str, value: MetricValue):
        """æ·»åŠ å€¼"""
        if isinstance(value, (int, float)):
            self._history[metric_name].append(value)
    
    def detect_anomaly(self, metric_name: str, current_value: MetricValue) -> bool:
        """æ£€æµ‹å¼‚å¸¸"""
        if not isinstance(current_value, (int, float)):
            return False
        
        history = self._history[metric_name]
        if len(history) < 10:  # éœ€è¦è¶³å¤Ÿçš„å†å²æ•°æ®
            return False
        
        try:
            mean = statistics.mean(history)
            std_dev = statistics.stdev(history)
            
            # ä½¿ç”¨Z-scoreæ£€æµ‹å¼‚å¸¸
            z_score = abs(current_value - mean) / max(std_dev, 0.001)
            return z_score > self.sensitivity
        except (statistics.StatisticsError, ZeroDivisionError):
            return False
    
    def get_anomaly_score(self, metric_name: str, current_value: MetricValue) -> float:
        """è·å–å¼‚å¸¸åˆ†æ•°"""
        if not isinstance(current_value, (int, float)):
            return 0.0
        
        history = self._history[metric_name]
        if len(history) < 10:
            return 0.0
        
        try:
            mean = statistics.mean(history)
            std_dev = statistics.stdev(history)
            z_score = abs(current_value - mean) / max(std_dev, 0.001)
            return min(z_score / self.sensitivity, 1.0)  # å½’ä¸€åŒ–åˆ°0-1
        except (statistics.StatisticsError, ZeroDivisionError):
            return 0.0


class PerformanceProfiler:
    """æ€§èƒ½åˆ†æå™¨"""
    
    def __init__(self):
        self._profiles: Dict[str, List[float]] = defaultdict(list)
        self._active_profiles: Dict[str, float] = {}
        self._lock = threading.Lock()
    
    @asynccontextmanager
    async def profile(self, operation_name: str):
        """æ€§èƒ½åˆ†æä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        start_time = time.time()
        
        with self._lock:
            self._active_profiles[operation_name] = start_time
        
        try:
            yield
        finally:
            end_time = time.time()
            duration = end_time - start_time
            
            with self._lock:
                self._profiles[operation_name].append(duration)
                self._active_profiles.pop(operation_name, None)
                
                # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
                if len(self._profiles[operation_name]) > 1000:
                    self._profiles[operation_name] = self._profiles[operation_name][-500:]
    
    def get_profile_stats(self, operation_name: str) -> Dict[str, float]:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        with self._lock:
            durations = self._profiles.get(operation_name, [])
            
            if not durations:
                return {}
            
            return {
                "count": len(durations),
                "total_time": sum(durations),
                "avg_time": statistics.mean(durations),
                "min_time": min(durations),
                "max_time": max(durations),
                "p50_time": np.percentile(durations, 50),
                "p95_time": np.percentile(durations, 95),
                "p99_time": np.percentile(durations, 99)
            }
    
    def get_all_profiles(self) -> Dict[str, Dict[str, float]]:
        """è·å–æ‰€æœ‰æ€§èƒ½ç»Ÿè®¡"""
        with self._lock:
            return {
                operation: self.get_profile_stats(operation)
                for operation in self._profiles.keys()
            }


class MetricsStorage:
    """æŒ‡æ ‡å­˜å‚¨"""
    
    def __init__(self, storage_path: str = "metrics_data"):
        self.storage_path = storage_path
        self._ensure_storage_directory()
    
    def _ensure_storage_directory(self):
        """ç¡®ä¿å­˜å‚¨ç›®å½•å­˜åœ¨"""
        import os
        os.makedirs(self.storage_path, exist_ok=True)
    
    async def store_metrics(self, metrics: Dict[str, MetricSeries]):
        """å­˜å‚¨æŒ‡æ ‡"""
        timestamp = datetime.now().strftime("%Y%m%d_%H")
        filename = f"{self.storage_path}/metrics_{timestamp}.json"
        
        # å‡†å¤‡æ•°æ®
        data = {
            "timestamp": time.time(),
            "metrics": {}
        }
        
        for name, series in metrics.items():
            data["metrics"][name] = {
                "name": series.name,
                "type": series.metric_type.value,
                "description": series.description,
                "unit": series.unit,
                "labels": series.labels,
                "points": [point.to_dict() for point in list(series.points)[-100:]]  # åªä¿å­˜æœ€è¿‘100ä¸ªç‚¹
            }
        
        # å¼‚æ­¥å†™å…¥æ–‡ä»¶
        try:
            async with aiofiles.open(filename, 'w', encoding='utf-8') as f:
                await f.write(json.dumps(data, indent=2, ensure_ascii=False))
        except Exception as e:
            logger.error(f"å­˜å‚¨æŒ‡æ ‡å¤±è´¥: {e}")
    
    async def load_metrics(self, hours_back: int = 24) -> Dict[str, List[MetricPoint]]:
        """åŠ è½½å†å²æŒ‡æ ‡"""
        import os
        import glob
        
        # è®¡ç®—æ—¶é—´èŒƒå›´
        end_time = datetime.now()
        start_time = end_time - timedelta(hours=hours_back)
        
        # æŸ¥æ‰¾ç›¸å…³æ–‡ä»¶
        pattern = f"{self.storage_path}/metrics_*.json"
        files = glob.glob(pattern)
        
        metrics_data = defaultdict(list)
        
        for file_path in files:
            try:
                # ä»æ–‡ä»¶åæå–æ—¶é—´
                basename = os.path.basename(file_path)
                time_str = basename.replace("metrics_", "").replace(".json", "")
                file_time = datetime.strptime(time_str, "%Y%m%d_%H")
                
                # æ£€æŸ¥æ˜¯å¦åœ¨æ—¶é—´èŒƒå›´å†…
                if start_time <= file_time <= end_time:
                    async with aiofiles.open(file_path, 'r', encoding='utf-8') as f:
                        content = await f.read()
                        data = json.loads(content)
                        
                        for metric_name, metric_data in data.get("metrics", {}).items():
                            for point_data in metric_data.get("points", []):
                                point = MetricPoint(
                                    timestamp=point_data["timestamp"],
                                    value=point_data["value"],
                                    labels=point_data.get("labels", {})
                                )
                                metrics_data[metric_name].append(point)
            
            except Exception as e:
                logger.warning(f"åŠ è½½æŒ‡æ ‡æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        return dict(metrics_data)


class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§ä¸»ç±»"""
    
    def __init__(
        self,
        system_collection_interval: float = 5.0,
        storage_interval: float = 300.0,  # 5åˆ†é’Ÿ
        enable_anomaly_detection: bool = True,
        enable_storage: bool = True
    ):
        self.system_collection_interval = system_collection_interval
        self.storage_interval = storage_interval
        self.enable_anomaly_detection = enable_anomaly_detection
        self.enable_storage = enable_storage
        
        # æ ¸å¿ƒç»„ä»¶
        self._metrics: Dict[str, MetricSeries] = {}
        self._alert_rules: Dict[str, AlertRule] = {}
        self._active_alerts: Dict[str, Alert] = {}
        self._alert_history: List[Alert] = []
        
        # æ”¶é›†å™¨
        self._system_collector = SystemMetricsCollector(system_collection_interval)
        self._app_collector = ApplicationMetricsCollector()
        
        # åˆ†æå™¨
        self._anomaly_detector = AnomalyDetector() if enable_anomaly_detection else None
        self._profiler = PerformanceProfiler()
        
        # å­˜å‚¨
        self._storage = MetricsStorage() if enable_storage else None
        
        # å›è°ƒå‡½æ•°
        self._alert_callbacks: List[Callable[[Alert], None]] = []
        self._metric_callbacks: List[Callable[[str, MetricValue], None]] = []
        
        # åå°ä»»åŠ¡
        self._running = False
        self._alert_task: Optional[asyncio.Task] = None
        self._storage_task: Optional[asyncio.Task] = None
        
        # è®¾ç½®ç³»ç»ŸæŒ‡æ ‡å›è°ƒ
        self._system_collector.set_metrics_callback(self._on_system_metrics)
        
        logger.info("æ€§èƒ½ç›‘æ§ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    async def start(self):
        """å¯åŠ¨ç›‘æ§ç³»ç»Ÿ"""
        if self._running:
            return
        
        self._running = True
        
        # å¯åŠ¨æ”¶é›†å™¨
        await self._system_collector.start()
        
        # å¯åŠ¨åå°ä»»åŠ¡
        self._alert_task = asyncio.create_task(self._alert_loop())
        
        if self.enable_storage:
            self._storage_task = asyncio.create_task(self._storage_loop())
        
        logger.info("æ€§èƒ½ç›‘æ§ç³»ç»Ÿå¯åŠ¨å®Œæˆ")
    
    async def stop(self, timeout: float = 30.0):
        """åœæ­¢ç›‘æ§ç³»ç»Ÿ"""
        if not self._running:
            return
        
        logger.info("å¼€å§‹åœæ­¢æ€§èƒ½ç›‘æ§ç³»ç»Ÿ...")
        self._running = False
        
        # åœæ­¢æ”¶é›†å™¨
        await self._system_collector.stop()
        
        # åœæ­¢åå°ä»»åŠ¡
        tasks = []
        if self._alert_task:
            tasks.append(self._alert_task)
        if self._storage_task:
            tasks.append(self._storage_task)
        
        for task in tasks:
            task.cancel()
        
        if tasks:
            try:
                await asyncio.wait_for(
                    asyncio.gather(*tasks, return_exceptions=True),
                    timeout=timeout
                )
            except asyncio.TimeoutError:
                logger.warning("åå°ä»»åŠ¡åœæ­¢è¶…æ—¶")
        
        # æœ€åä¸€æ¬¡å­˜å‚¨
        if self.enable_storage and self._storage:
            try:
                await self._storage.store_metrics(self._metrics)
            except Exception as e:
                logger.error(f"æœ€ç»ˆå­˜å‚¨å¤±è´¥: {e}")
        
        logger.info("æ€§èƒ½ç›‘æ§ç³»ç»Ÿåœæ­¢å®Œæˆ")
    
    def record_metric(
        self,
        name: str,
        value: MetricValue,
        metric_type: MetricType = MetricType.GAUGE,
        description: str = "",
        unit: str = "",
        labels: Optional[Dict[str, str]] = None,
        timestamp: Optional[float] = None
    ):
        """è®°å½•æŒ‡æ ‡"""
        # è·å–æˆ–åˆ›å»ºæŒ‡æ ‡åºåˆ—
        if name not in self._metrics:
            self._metrics[name] = MetricSeries(
                name=name,
                metric_type=metric_type,
                description=description,
                unit=unit,
                labels=labels or {}
            )
        
        # æ·»åŠ æ•°æ®ç‚¹
        series = self._metrics[name]
        series.add_point(value, timestamp, labels)
        
        # å¼‚å¸¸æ£€æµ‹
        if self._anomaly_detector:
            self._anomaly_detector.add_value(name, value)
            
            if self._anomaly_detector.detect_anomaly(name, value):
                anomaly_score = self._anomaly_detector.get_anomaly_score(name, value)
                logger.warning(f"æ£€æµ‹åˆ°æŒ‡æ ‡å¼‚å¸¸: {name}={value}, å¼‚å¸¸åˆ†æ•°: {anomaly_score:.3f}")
                
                # åˆ›å»ºå¼‚å¸¸å‘Šè­¦
                self._create_anomaly_alert(name, value, anomaly_score)
        
        # è§¦å‘å›è°ƒ
        for callback in self._metric_callbacks:
            try:
                callback(name, value)
            except Exception as e:
                logger.error(f"æŒ‡æ ‡å›è°ƒå‡ºé”™: {e}")
    
    def _on_system_metrics(self, metrics: Dict[str, MetricValue]):
        """ç³»ç»ŸæŒ‡æ ‡å›è°ƒ"""
        for name, value in metrics.items():
            self.record_metric(
                name=name,
                value=value,
                metric_type=MetricType.GAUGE,
                description=f"ç³»ç»ŸæŒ‡æ ‡: {name}"
            )
    
    def record_application_metrics(self):
        """è®°å½•åº”ç”¨æŒ‡æ ‡"""
        app_metrics = self._app_collector.get_metrics()
        for name, value in app_metrics.items():
            self.record_metric(
                name=name,
                value=value,
                metric_type=MetricType.GAUGE,
                description=f"åº”ç”¨æŒ‡æ ‡: {name}"
            )
    
    def get_application_collector(self) -> ApplicationMetricsCollector:
        """è·å–åº”ç”¨æŒ‡æ ‡æ”¶é›†å™¨"""
        return self._app_collector
    
    def get_profiler(self) -> PerformanceProfiler:
        """è·å–æ€§èƒ½åˆ†æå™¨"""
        return self._profiler
    
    def add_alert_rule(
        self,
        name: str,
        metric_name: str,
        condition: str,
        threshold: MetricValue,
        level: AlertLevel = AlertLevel.WARNING,
        duration: float = 60.0,
        labels: Optional[Dict[str, str]] = None
    ) -> str:
        """æ·»åŠ å‘Šè­¦è§„åˆ™"""
        rule_id = str(uuid.uuid4())
        rule = AlertRule(
            rule_id=rule_id,
            name=name,
            description=f"å‘Šè­¦è§„åˆ™: {name}",
            metric_name=metric_name,
            condition=condition,
            threshold=threshold,
            level=level,
            duration=duration,
            labels=labels or {}
        )
        
        self._alert_rules[rule_id] = rule
        logger.info(f"æ·»åŠ å‘Šè­¦è§„åˆ™: {name} ({rule_id})")
        return rule_id
    
    def remove_alert_rule(self, rule_id: str):
        """ç§»é™¤å‘Šè­¦è§„åˆ™"""
        if rule_id in self._alert_rules:
            rule = self._alert_rules.pop(rule_id)
            logger.info(f"ç§»é™¤å‘Šè­¦è§„åˆ™: {rule.name} ({rule_id})")
    
    def add_alert_callback(self, callback: Callable[[Alert], None]):
        """æ·»åŠ å‘Šè­¦å›è°ƒ"""
        self._alert_callbacks.append(callback)
    
    def add_metric_callback(self, callback: Callable[[str, MetricValue], None]):
        """æ·»åŠ æŒ‡æ ‡å›è°ƒ"""
        self._metric_callbacks.append(callback)
    
    def _create_anomaly_alert(self, metric_name: str, value: MetricValue, anomaly_score: float):
        """åˆ›å»ºå¼‚å¸¸å‘Šè­¦"""
        alert_id = f"anomaly_{metric_name}_{int(time.time())}"
        
        # ç¡®å®šå‘Šè­¦çº§åˆ«
        if anomaly_score > 0.8:
            level = AlertLevel.CRITICAL
        elif anomaly_score > 0.6:
            level = AlertLevel.ERROR
        else:
            level = AlertLevel.WARNING
        
        alert = Alert(
            alert_id=alert_id,
            name=f"å¼‚å¸¸æ£€æµ‹: {metric_name}",
            description=f"æŒ‡æ ‡ {metric_name} æ£€æµ‹åˆ°å¼‚å¸¸å€¼ {value}ï¼Œå¼‚å¸¸åˆ†æ•°: {anomaly_score:.3f}",
            level=level,
            metric_name=metric_name,
            current_value=value,
            labels={"type": "anomaly", "metric": metric_name}
        )
        
        self._trigger_alert(alert)
    
    def _trigger_alert(self, alert: Alert):
        """è§¦å‘å‘Šè­¦"""
        self._active_alerts[alert.alert_id] = alert
        self._alert_history.append(alert)
        
        # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
        if len(self._alert_history) > 1000:
            self._alert_history = self._alert_history[-500:]
        
        logger.warning(f"è§¦å‘å‘Šè­¦: {alert.name} ({alert.level.value})")
        
        # è§¦å‘å›è°ƒ
        for callback in self._alert_callbacks:
            try:
                callback(alert)
            except Exception as e:
                logger.error(f"å‘Šè­¦å›è°ƒå‡ºé”™: {e}")
    
    async def _alert_loop(self):
        """å‘Šè­¦æ£€æŸ¥å¾ªç¯"""
        logger.info("å‘Šè­¦æ£€æŸ¥ä»»åŠ¡å¯åŠ¨")
        
        while self._running:
            try:
                await self._check_alert_rules()
                await asyncio.sleep(10.0)  # æ¯10ç§’æ£€æŸ¥ä¸€æ¬¡
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"å‘Šè­¦æ£€æŸ¥å‡ºé”™: {e}")
        
        logger.info("å‘Šè­¦æ£€æŸ¥ä»»åŠ¡åœæ­¢")
    
    async def _check_alert_rules(self):
        """æ£€æŸ¥å‘Šè­¦è§„åˆ™"""
        for rule in self._alert_rules.values():
            if not rule.enabled:
                continue
            
            # è·å–æŒ‡æ ‡å½“å‰å€¼
            metric_series = self._metrics.get(rule.metric_name)
            if not metric_series:
                continue
            
            current_value = metric_series.get_latest_value()
            if current_value is None:
                continue
            
            # è¯„ä¼°å‘Šè­¦æ¡ä»¶
            if rule.evaluate(current_value):
                # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ´»è·ƒå‘Šè­¦
                existing_alert = None
                for alert in self._active_alerts.values():
                    if (alert.metric_name == rule.metric_name and 
                        alert.status == AlertStatus.ACTIVE and
                        "rule_id" in alert.labels and
                        alert.labels["rule_id"] == rule.rule_id):
                        existing_alert = alert
                        break
                
                if not existing_alert:
                    # åˆ›å»ºæ–°å‘Šè­¦
                    alert_id = f"rule_{rule.rule_id}_{int(time.time())}"
                    alert = Alert(
                        alert_id=alert_id,
                        name=rule.name,
                        description=rule.description,
                        level=rule.level,
                        metric_name=rule.metric_name,
                        threshold_value=rule.threshold,
                        current_value=current_value,
                        labels={**rule.labels, "rule_id": rule.rule_id}
                    )
                    
                    self._trigger_alert(alert)
            else:
                # è§£å†³ç›¸å…³å‘Šè­¦
                alerts_to_resolve = [
                    alert for alert in self._active_alerts.values()
                    if (alert.metric_name == rule.metric_name and
                        alert.status == AlertStatus.ACTIVE and
                        "rule_id" in alert.labels and
                        alert.labels["rule_id"] == rule.rule_id)
                ]
                
                for alert in alerts_to_resolve:
                    alert.resolve()
                    logger.info(f"è§£å†³å‘Šè­¦: {alert.name} ({alert.alert_id})")
    
    async def _storage_loop(self):
        """å­˜å‚¨å¾ªç¯"""
        logger.info("æŒ‡æ ‡å­˜å‚¨ä»»åŠ¡å¯åŠ¨")
        
        while self._running:
            try:
                if self._storage:
                    await self._storage.store_metrics(self._metrics)
                
                await asyncio.sleep(self.storage_interval)
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"æŒ‡æ ‡å­˜å‚¨å‡ºé”™: {e}")
        
        logger.info("æŒ‡æ ‡å­˜å‚¨ä»»åŠ¡åœæ­¢")
    
    def get_metrics_summary(self) -> Dict[str, Any]:
        """è·å–æŒ‡æ ‡æ‘˜è¦"""
        summary = {
            "total_metrics": len(self._metrics),
            "active_alerts": len([a for a in self._active_alerts.values() if a.status == AlertStatus.ACTIVE]),
            "total_alert_rules": len(self._alert_rules),
            "metrics": {}
        }
        
        for name, series in self._metrics.items():
            latest_value = series.get_latest_value()
            stats = series.calculate_statistics()
            
            summary["metrics"][name] = {
                "latest_value": latest_value,
                "type": series.metric_type.value,
                "description": series.description,
                "unit": series.unit,
                "statistics": stats
            }
        
        return summary
    
    def get_alerts_summary(self) -> Dict[str, Any]:
        """è·å–å‘Šè­¦æ‘˜è¦"""
        active_alerts = [a for a in self._active_alerts.values() if a.status == AlertStatus.ACTIVE]
        
        return {
            "active_alerts_count": len(active_alerts),
            "total_alerts_count": len(self._alert_history),
            "alerts_by_level": {
                level.value: len([a for a in active_alerts if a.level == level])
                for level in AlertLevel
            },
            "active_alerts": [alert.to_dict() for alert in active_alerts[:10]],  # æœ€è¿‘10ä¸ª
            "recent_alerts": [alert.to_dict() for alert in self._alert_history[-10:]]  # æœ€è¿‘10ä¸ª
        }
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æ‘˜è¦"""
        profiles = self._profiler.get_all_profiles()
        
        return {
            "total_operations": len(profiles),
            "profiles": profiles
        }


if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    async def main():
        """ä¸»å‡½æ•°ç¤ºä¾‹"""
        # åˆ›å»ºæ€§èƒ½ç›‘æ§å™¨
        monitor = PerformanceMonitor(
            system_collection_interval=2.0,
            enable_anomaly_detection=True,
            enable_storage=True
        )
        
        # æ·»åŠ å‘Šè­¦è§„åˆ™
        monitor.add_alert_rule(
            name="CPUä½¿ç”¨ç‡è¿‡é«˜",
            metric_name="system.cpu.usage_percent",
            condition=">",
            threshold=80.0,
            level=AlertLevel.WARNING
        )
        
        monitor.add_alert_rule(
            name="å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜",
            metric_name="system.memory.usage_percent",
            condition=">",
            threshold=90.0,
            level=AlertLevel.ERROR
        )
        
        # æ·»åŠ å‘Šè­¦å›è°ƒ
        def alert_handler(alert: Alert):
            print(f"ğŸš¨ å‘Šè­¦: {alert.name} - {alert.description}")
        
        monitor.add_alert_callback(alert_handler)
        
        try:
            await monitor.start()
            
            # è·å–åº”ç”¨æŒ‡æ ‡æ”¶é›†å™¨å’Œæ€§èƒ½åˆ†æå™¨
            app_collector = monitor.get_application_collector()
            profiler = monitor.get_profiler()
            
            print("æ€§èƒ½ç›‘æ§ç³»ç»Ÿå¯åŠ¨ï¼Œå¼€å§‹æ¨¡æ‹Ÿå·¥ä½œè´Ÿè½½...")
            
            # æ¨¡æ‹Ÿä¸€äº›å·¥ä½œè´Ÿè½½
            for i in range(20):
                # æ¨¡æ‹Ÿè¯·æ±‚å¤„ç†
                app_collector.start_request()
                
                async with profiler.profile("api_request"):
                    # æ¨¡æ‹ŸAPIå¤„ç†æ—¶é—´
                    await asyncio.sleep(0.1 + (i % 3) * 0.05)
                    
                    # æ¨¡æ‹Ÿé”™è¯¯
                    is_error = i % 10 == 0
                    response_time = 0.1 + (i % 3) * 0.05
                    app_collector.record_request(response_time, is_error)
                
                app_collector.end_request()
                
                # è®°å½•è‡ªå®šä¹‰æŒ‡æ ‡
                monitor.record_metric(
                    "custom.queue_size",
                    i * 2,
                    MetricType.GAUGE,
                    "é˜Ÿåˆ—å¤§å°",
                    "items"
                )
                
                # è®°å½•åº”ç”¨æŒ‡æ ‡
                monitor.record_application_metrics()
                
                await asyncio.sleep(1.0)
            
            # ç­‰å¾…ä¸€æ®µæ—¶é—´è®©ç›‘æ§ç³»ç»Ÿæ”¶é›†æ•°æ®
            await asyncio.sleep(10)
            
            # æ‰“å°æ‘˜è¦
            print("\n=== æŒ‡æ ‡æ‘˜è¦ ===")
            metrics_summary = monitor.get_metrics_summary()
            print(f"æ€»æŒ‡æ ‡æ•°: {metrics_summary['total_metrics']}")
            print(f"æ´»è·ƒå‘Šè­¦æ•°: {metrics_summary['active_alerts']}")
            
            print("\n=== å…³é”®æŒ‡æ ‡ ===")
            key_metrics = [
                "system.cpu.usage_percent",
                "system.memory.usage_percent",
                "app.requests.total",
                "app.requests.error_rate",
                "app.response_time.avg"
            ]
            
            for metric_name in key_metrics:
                if metric_name in metrics_summary["metrics"]:
                    metric_info = metrics_summary["metrics"][metric_name]
                    print(f"  {metric_name}: {metric_info['latest_value']:.2f} {metric_info['unit']}")
            
            print("\n=== å‘Šè­¦æ‘˜è¦ ===")
            alerts_summary = monitor.get_alerts_summary()
            print(f"æ´»è·ƒå‘Šè­¦: {alerts_summary['active_alerts_count']}")
            print(f"æ€»å‘Šè­¦æ•°: {alerts_summary['total_alerts_count']}")
            
            print("\n=== æ€§èƒ½åˆ†æ ===")
            perf_summary = monitor.get_performance_summary()
            for operation, stats in perf_summary["profiles"].items():
                if stats:
                    print(f"  {operation}:")
                    print(f"    è°ƒç”¨æ¬¡æ•°: {stats['count']}")
                    print(f"    å¹³å‡æ—¶é—´: {stats['avg_time']:.3f}s")
                    print(f"    P95æ—¶é—´: {stats['p95_time']:.3f}s")
        
        finally:
            await monitor.stop()
    
    # è¿è¡Œç¤ºä¾‹
    asyncio.run(main())